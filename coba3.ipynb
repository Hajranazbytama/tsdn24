{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetes_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  HighChol  CholCheck   BMI  Smoker  HeartDiseaseorAttack  \\\n",
       "0   4.0  1.0       0.0        1.0  26.0     0.0                   0.0   \n",
       "1  12.0  1.0       1.0        1.0  26.0     1.0                   0.0   \n",
       "2  13.0  1.0       0.0        1.0  26.0     0.0                   0.0   \n",
       "3  11.0  1.0       1.0        1.0  28.0     1.0                   0.0   \n",
       "4   8.0  0.0       0.0        1.0  29.0     1.0                   0.0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  HvyAlcoholConsump  GenHlth  MentHlth  \\\n",
       "0           1.0     0.0      1.0                0.0      3.0       5.0   \n",
       "1           0.0     1.0      0.0                0.0      3.0       0.0   \n",
       "2           1.0     1.0      1.0                0.0      1.0       0.0   \n",
       "3           1.0     1.0      1.0                0.0      3.0       0.0   \n",
       "4           1.0     1.0      1.0                0.0      2.0       0.0   \n",
       "\n",
       "   PhysHlth  DiffWalk  Stroke  HighBP  Diabetes  \n",
       "0      30.0       0.0     0.0     1.0       0.0  \n",
       "1       0.0       0.0     1.0     1.0       0.0  \n",
       "2      10.0       0.0     0.0     0.0       0.0  \n",
       "3       3.0       0.0     0.0     1.0       0.0  \n",
       "4       0.0       0.0     0.0     0.0       0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Age                   70692 non-null  float64\n",
      " 1   Sex                   70692 non-null  float64\n",
      " 2   HighChol              70692 non-null  float64\n",
      " 3   CholCheck             70692 non-null  float64\n",
      " 4   BMI                   70692 non-null  float64\n",
      " 5   Smoker                70692 non-null  float64\n",
      " 6   HeartDiseaseorAttack  70692 non-null  float64\n",
      " 7   PhysActivity          70692 non-null  float64\n",
      " 8   Fruits                70692 non-null  float64\n",
      " 9   Veggies               70692 non-null  float64\n",
      " 10  HvyAlcoholConsump     70692 non-null  float64\n",
      " 11  GenHlth               70692 non-null  float64\n",
      " 12  MentHlth              70692 non-null  float64\n",
      " 13  PhysHlth              70692 non-null  float64\n",
      " 14  DiffWalk              70692 non-null  float64\n",
      " 15  Stroke                70692 non-null  float64\n",
      " 16  HighBP                70692 non-null  float64\n",
      " 17  Diabetes              70692 non-null  float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 9.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                     0\n",
       "Sex                     0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "BMI                     0\n",
       "Smoker                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "Fruits                  0\n",
       "Veggies                 0\n",
       "HvyAlcoholConsump       0\n",
       "GenHlth                 0\n",
       "MentHlth                0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Stroke                  0\n",
       "HighBP                  0\n",
       "Diabetes                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "70687    False\n",
       "70688    False\n",
       "70689    False\n",
       "70690    False\n",
       "70691    False\n",
       "Length: 70692, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70687</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70688</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70689</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70690</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70691</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64020 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Sex  HighChol  CholCheck   BMI  Smoker  HeartDiseaseorAttack  \\\n",
       "0       4.0  1.0       0.0        1.0  26.0     0.0                   0.0   \n",
       "1      12.0  1.0       1.0        1.0  26.0     1.0                   0.0   \n",
       "2      13.0  1.0       0.0        1.0  26.0     0.0                   0.0   \n",
       "3      11.0  1.0       1.0        1.0  28.0     1.0                   0.0   \n",
       "4       8.0  0.0       0.0        1.0  29.0     1.0                   0.0   \n",
       "...     ...  ...       ...        ...   ...     ...                   ...   \n",
       "70687   6.0  0.0       1.0        1.0  37.0     0.0                   0.0   \n",
       "70688  10.0  1.0       1.0        1.0  29.0     1.0                   1.0   \n",
       "70689  13.0  0.0       1.0        1.0  25.0     0.0                   1.0   \n",
       "70690  11.0  0.0       1.0        1.0  18.0     0.0                   0.0   \n",
       "70691   9.0  0.0       1.0        1.0  25.0     0.0                   1.0   \n",
       "\n",
       "       PhysActivity  Fruits  Veggies  HvyAlcoholConsump  GenHlth  MentHlth  \\\n",
       "0               1.0     0.0      1.0                0.0      3.0       5.0   \n",
       "1               0.0     1.0      0.0                0.0      3.0       0.0   \n",
       "2               1.0     1.0      1.0                0.0      1.0       0.0   \n",
       "3               1.0     1.0      1.0                0.0      3.0       0.0   \n",
       "4               1.0     1.0      1.0                0.0      2.0       0.0   \n",
       "...             ...     ...      ...                ...      ...       ...   \n",
       "70687           0.0     0.0      1.0                0.0      4.0       0.0   \n",
       "70688           0.0     1.0      1.0                0.0      2.0       0.0   \n",
       "70689           0.0     1.0      0.0                0.0      5.0      15.0   \n",
       "70690           0.0     0.0      0.0                0.0      4.0       0.0   \n",
       "70691           1.0     1.0      0.0                0.0      2.0       0.0   \n",
       "\n",
       "       PhysHlth  DiffWalk  Stroke  HighBP  Diabetes  \n",
       "0          30.0       0.0     0.0     1.0       0.0  \n",
       "1           0.0       0.0     1.0     1.0       0.0  \n",
       "2          10.0       0.0     0.0     0.0       0.0  \n",
       "3           3.0       0.0     0.0     1.0       0.0  \n",
       "4           0.0       0.0     0.0     0.0       0.0  \n",
       "...         ...       ...     ...     ...       ...  \n",
       "70687       0.0       0.0     0.0     0.0       1.0  \n",
       "70688       0.0       1.0     0.0     0.0       1.0  \n",
       "70689       0.0       1.0     0.0     1.0       1.0  \n",
       "70690       0.0       1.0     0.0     1.0       1.0  \n",
       "70691       0.0       0.0     0.0     1.0       1.0  \n",
       "\n",
       "[64020 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "variabel_numerik = data.columns.difference(['BMI', 'MentHlth', 'PhysHlth'])\n",
    "data[variabel_numerik] = data[variabel_numerik].astype('category')\n",
    "data[variabel_numerik] = data[variabel_numerik].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>7.584055</td>\n",
       "      <td>2.852153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.456997</td>\n",
       "      <td>0.498151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.525703</td>\n",
       "      <td>0.499342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>0.155336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>29.856985</td>\n",
       "      <td>7.113954</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.499392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.354914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.703036</td>\n",
       "      <td>0.456924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.611795</td>\n",
       "      <td>0.487345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.788774</td>\n",
       "      <td>0.408181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.042721</td>\n",
       "      <td>0.202228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>1.837082</td>\n",
       "      <td>1.113565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>3.752037</td>\n",
       "      <td>8.155627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>5.810417</td>\n",
       "      <td>10.062261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalk</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.252730</td>\n",
       "      <td>0.434581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.241468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.563458</td>\n",
       "      <td>0.495960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>70692.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count       mean        std   min   25%   50%   75%  \\\n",
       "Age                   70692.0   7.584055   2.852153   0.0   6.0   8.0  10.0   \n",
       "Sex                   70692.0   0.456997   0.498151   0.0   0.0   0.0   1.0   \n",
       "HighChol              70692.0   0.525703   0.499342   0.0   0.0   1.0   1.0   \n",
       "CholCheck             70692.0   0.975259   0.155336   0.0   1.0   1.0   1.0   \n",
       "BMI                   70692.0  29.856985   7.113954  12.0  25.0  29.0  33.0   \n",
       "Smoker                70692.0   0.475273   0.499392   0.0   0.0   0.0   1.0   \n",
       "HeartDiseaseorAttack  70692.0   0.147810   0.354914   0.0   0.0   0.0   0.0   \n",
       "PhysActivity          70692.0   0.703036   0.456924   0.0   0.0   1.0   1.0   \n",
       "Fruits                70692.0   0.611795   0.487345   0.0   0.0   1.0   1.0   \n",
       "Veggies               70692.0   0.788774   0.408181   0.0   1.0   1.0   1.0   \n",
       "HvyAlcoholConsump     70692.0   0.042721   0.202228   0.0   0.0   0.0   0.0   \n",
       "GenHlth               70692.0   1.837082   1.113565   0.0   1.0   2.0   3.0   \n",
       "MentHlth              70692.0   3.752037   8.155627   0.0   0.0   0.0   2.0   \n",
       "PhysHlth              70692.0   5.810417  10.062261   0.0   0.0   0.0   6.0   \n",
       "DiffWalk              70692.0   0.252730   0.434581   0.0   0.0   0.0   1.0   \n",
       "Stroke                70692.0   0.062171   0.241468   0.0   0.0   0.0   0.0   \n",
       "HighBP                70692.0   0.563458   0.495960   0.0   0.0   1.0   1.0   \n",
       "Diabetes              70692.0   0.500000   0.500004   0.0   0.0   0.5   1.0   \n",
       "\n",
       "                       max  \n",
       "Age                   12.0  \n",
       "Sex                    1.0  \n",
       "HighChol               1.0  \n",
       "CholCheck              1.0  \n",
       "BMI                   98.0  \n",
       "Smoker                 1.0  \n",
       "HeartDiseaseorAttack   1.0  \n",
       "PhysActivity           1.0  \n",
       "Fruits                 1.0  \n",
       "Veggies                1.0  \n",
       "HvyAlcoholConsump      1.0  \n",
       "GenHlth                4.0  \n",
       "MentHlth              30.0  \n",
       "PhysHlth              30.0  \n",
       "DiffWalk               1.0  \n",
       "Stroke                 1.0  \n",
       "HighBP                 1.0  \n",
       "Diabetes               1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  HighChol  CholCheck   BMI  Smoker  HeartDiseaseorAttack  \\\n",
       "0    3    1         0          1  26.0       0                     0   \n",
       "1   11    1         1          1  26.0       1                     0   \n",
       "2   12    1         0          1  26.0       0                     0   \n",
       "3   10    1         1          1  28.0       1                     0   \n",
       "4    7    0         0          1  29.0       1                     0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  HvyAlcoholConsump  GenHlth  MentHlth  \\\n",
       "0             1       0        1                  0        2       5.0   \n",
       "1             0       1        0                  0        2       0.0   \n",
       "2             1       1        1                  0        0       0.0   \n",
       "3             1       1        1                  0        2       0.0   \n",
       "4             1       1        1                  0        1       0.0   \n",
       "\n",
       "   PhysHlth  DiffWalk  Stroke  HighBP  Diabetes  \n",
       "0      30.0         0       0       1         0  \n",
       "1       0.0         0       1       1         0  \n",
       "2      10.0         0       0       0         0  \n",
       "3       3.0         0       0       1         0  \n",
       "4       0.0         0       0       0         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "0    35346\n",
       "1    35346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Diabetes\"], axis = 1)\n",
    "y = data[\"Diabetes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "['GenHlth', 'HighBP', 'BMI', 'HighChol', 'Age', 'DiffWalk', 'PhysHlth', 'HeartDiseaseorAttack']\n"
     ]
    }
   ],
   "source": [
    "# Calculate information gain\n",
    "ig = mutual_info_classif(X, y)\n",
    "\n",
    "# Create dictionary to store information gain values\n",
    "ig_dict = {}\n",
    "for i in range(len(X.columns)):\n",
    "    ig_dict[X.columns[i]] = ig[i]\n",
    "\n",
    "# Sort features by information gain in descending order\n",
    "ig_dict_sorted = dict(sorted(ig_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Select the top n features\n",
    "n = 8\n",
    "selected_features = list(ig_dict_sorted.keys())[:n]\n",
    "\n",
    "X_infgain = X[selected_features]\n",
    "\n",
    "print('Selected Features:')\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the information gain of each feature\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.barplot(x=list(ig_dict_sorted.values()), y=list(ig_dict_sorted.keys()))\n",
    "plt.title('Information Gain of Features')\n",
    "plt.xlabel('Information Gain')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFECV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "      estimator=LogisticRegression(random_state=42), scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFECV</label><div class=\"sk-toggleable__content\"><pre>RFECV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "      estimator=LogisticRegression(random_state=42), scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "      estimator=LogisticRegression(random_state=42), scoring='accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LogisticRegression(random_state=42)\n",
    "rfecv = RFECV(estimator=estimator, cv=StratifiedKFold(10, random_state=42, shuffle=True), scoring=\"accuracy\")\n",
    "rfecv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of features: 16\n"
     ]
    }
   ],
   "source": [
    "# Plotting the Recursive Feature Elimination (RFE) cross-validation scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'], marker='o')\n",
    "plt.grid()\n",
    "plt.xticks(range(1, X.shape[1] + 1))\n",
    "plt.xlabel(\"Number of Selected Features\")\n",
    "plt.ylabel(\"CV Score\")\n",
    "plt.title(\"Recursive Feature Elimination (RFE)\")\n",
    "plt.show()\n",
    "\n",
    "# Display the optimal number of features\n",
    "print(\"The optimal number of features: {}\".format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfe = X.iloc[:, rfecv.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HighBP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  HighChol  CholCheck   BMI  HeartDiseaseorAttack  PhysActivity  \\\n",
       "0    3    1         0          1  26.0                     0             1   \n",
       "1   11    1         1          1  26.0                     0             0   \n",
       "2   12    1         0          1  26.0                     0             1   \n",
       "3   10    1         1          1  28.0                     0             1   \n",
       "4    7    0         0          1  29.0                     0             1   \n",
       "\n",
       "   Fruits  Veggies  HvyAlcoholConsump  GenHlth  MentHlth  PhysHlth  DiffWalk  \\\n",
       "0       0        1                  0        2       5.0      30.0         0   \n",
       "1       1        0                  0        2       0.0       0.0         0   \n",
       "2       1        1                  0        0       0.0      10.0         0   \n",
       "3       1        1                  0        2       0.0       3.0         0   \n",
       "4       1        1                  0        1       0.0       0.0         0   \n",
       "\n",
       "   Stroke  HighBP  \n",
       "0       0       1  \n",
       "1       1       1  \n",
       "2       0       0  \n",
       "3       0       1  \n",
       "4       0       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "0    35346\n",
       "1    35346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=\"Diabetes\", data=data, width=0.6, edgecolor=\"black\")  \n",
    "plt.xticks([0, 1], labels=[1, 2])       \n",
    "plt.xlabel(\"COPD Stages\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"COPD Distribution by Stages\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_infgain, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "1    28277\n",
       "0    28276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.73      7070\n",
      "           1       0.72      0.77      0.75      7069\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.74      0.74      0.74     14139\n",
      "weighted avg       0.74      0.74      0.74     14139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "xg = XGBClassifier(n_estimators=350)\n",
    "\n",
    "# Fit the model\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "xg_preds = xg.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, xg_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28277, number of negative: 28276\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 128\n",
      "[LightGBM] [Info] Number of data points in the train set: 56553, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500009 -> initscore=0.000035\n",
      "[LightGBM] [Info] Start training from score 0.000035\n",
      "LightGBM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73      7070\n",
      "           1       0.72      0.79      0.75      7069\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.75      0.74      0.74     14139\n",
      "weighted avg       0.75      0.74      0.74     14139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the LightGBM classifier\n",
    "lgbm = LGBMClassifier(n_estimators=350, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lgbm_preds = lgbm.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"LightGBM Classification Report:\")\n",
    "print(classification_report(y_test, lgbm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      7070\n",
      "           1       0.73      0.77      0.75      7069\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.74      0.74      0.74     14139\n",
      "weighted avg       0.74      0.74      0.74     14139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # A simple base estimator for AdaBoost\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the AdaBoost classifier with a decision tree as the base estimator\n",
    "ada = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1),  # A weak classifier, can be adjusted\n",
    "    n_estimators=350,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ada_preds = ada.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"AdaBoost Classification Report:\")\n",
    "print(classification_report(y_test, ada_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      7070\n",
      "           1       0.74      0.77      0.75      7069\n",
      "\n",
      "    accuracy                           0.75     14139\n",
      "   macro avg       0.75      0.75      0.75     14139\n",
      "weighted avg       0.75      0.75      0.75     14139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the GradientBoostingClassifier with the specified parameters\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=20,  # Number of boosting stages (trees)\n",
    "    learning_rate=0.5,  # Step size shrinking to prevent overfitting\n",
    "    max_features=2,  # Maximum number of features to consider for each tree\n",
    "    max_depth=2,  # Maximum depth of individual trees\n",
    "    random_state=0  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation/test data\n",
    "predictions = gb.predict(X_test)\n",
    "\n",
    "# Print the classification report to evaluate the performance\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Training XGBoost...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73      7070\n",
      "           1       0.73      0.79      0.75      7069\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.75      0.74      0.74     14139\n",
      "weighted avg       0.75      0.74      0.74     14139\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73      7070\n",
      "           1       0.73      0.79      0.75      7069\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.75      0.74      0.74     14139\n",
      "weighted avg       0.75      0.74      0.74     14139\n",
      "\n",
      "\n",
      "Training Bagging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.74      7070\n",
      "           1       0.73      0.79      0.76      7069\n",
      "\n",
      "    accuracy                           0.75     14139\n",
      "   macro avg       0.75      0.75      0.75     14139\n",
      "weighted avg       0.75      0.75      0.75     14139\n",
      "\n",
      "\n",
      "Training Ensemble Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73      7070\n",
      "           1       0.72      0.79      0.76      7069\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.75      0.74      0.74     14139\n",
      "weighted avg       0.75      0.74      0.74     14139\n",
      "\n",
      "Tuning XGBoost...\n",
      "Tuning Gradient Boosting...\n",
      "XGBoost best parameters: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.6}\n",
      "XGBoost best score: 0.7485897275650308\n",
      "\n",
      "Gradient Boosting best parameters: {'subsample': 0.6, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 5, 'learning_rate': 0.05}\n",
      "Gradient Boosting best score: 0.7480592501638234\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluasi model dan tampilkan classification report\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "def train_xgboost(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    XGBoost dengan parameter yang dioptimasi\n",
    "    \"\"\"\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        min_child_weight=1,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=1,\n",
    "        tree_method='hist',\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return evaluate_model(xgb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "def train_gradient_boosting(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Gradient Boosting dengan parameter yang dioptimasi\n",
    "    \"\"\"\n",
    "    gb_model = GradientBoostingClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=3,\n",
    "        subsample=0.8,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    )\n",
    "    return evaluate_model(gb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "def train_bagging(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Bagging dengan XGBoost sebagai base estimator\n",
    "    \"\"\"\n",
    "    base_estimator = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    bag_model = BaggingClassifier(\n",
    "        base_estimator=base_estimator,\n",
    "        n_estimators=10,\n",
    "        max_samples=0.8,\n",
    "        max_features=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return evaluate_model(bag_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "def train_ensemble(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Voting Ensemble dari ketiga model\n",
    "    \"\"\"\n",
    "    # Define base models\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    bag = BaggingClassifier(\n",
    "        base_estimator=XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5\n",
    "        ),\n",
    "        n_estimators=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create voting classifier\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('xgb', xgb),\n",
    "            ('gb', gb),\n",
    "            ('bag', bag)\n",
    "        ],\n",
    "        voting='soft'\n",
    "    )\n",
    "    \n",
    "    return evaluate_model(ensemble, X_train, X_test, y_train, y_test)\n",
    "\n",
    "def preprocess_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Preprocessing data menggunakan StandardScaler\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def improve_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Pipeline utama untuk training dan evaluasi model\n",
    "    \"\"\"\n",
    "    # 1. Preprocess data\n",
    "    print(\"Preprocessing data...\")\n",
    "    X_train_scaled, X_test_scaled = preprocess_data(X_train, X_test)\n",
    "    \n",
    "    # 2. Train XGBoost\n",
    "    print(\"\\nTraining XGBoost...\")\n",
    "    xgb_model = train_xgboost(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    # 3. Train Gradient Boosting\n",
    "    print(\"\\nTraining Gradient Boosting...\")\n",
    "    gb_model = train_gradient_boosting(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    # 4. Train Bagging\n",
    "    print(\"\\nTraining Bagging...\")\n",
    "    bag_model = train_bagging(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    # 5. Train Ensemble\n",
    "    print(\"\\nTraining Ensemble Model...\")\n",
    "    ensemble_model = train_ensemble(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    return xgb_model, gb_model, bag_model, ensemble_model\n",
    "\n",
    "def tune_models(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Hyperparameter tuning untuk semua model\n",
    "    \"\"\"\n",
    "    # XGBoost parameters\n",
    "    xgb_params = {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0, 0.1, 0.2]\n",
    "    }\n",
    "    \n",
    "    # Gradient Boosting parameters\n",
    "    gb_params = {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "    \n",
    "    # Tuning XGBoost\n",
    "    print(\"Tuning XGBoost...\")\n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    xgb_search = RandomizedSearchCV(xgb, xgb_params, n_iter=20, cv=5, \n",
    "                                  scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "    xgb_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Tuning Gradient Boosting\n",
    "    print(\"Tuning Gradient Boosting...\")\n",
    "    gb = GradientBoostingClassifier(random_state=42)\n",
    "    gb_search = RandomizedSearchCV(gb, gb_params, n_iter=20, cv=5, \n",
    "                                 scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "    gb_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"XGBoost best parameters:\", xgb_search.best_params_)\n",
    "    print(\"XGBoost best score:\", xgb_search.best_score_)\n",
    "    print(\"\\nGradient Boosting best parameters:\", gb_search.best_params_)\n",
    "    print(\"Gradient Boosting best score:\", gb_search.best_score_)\n",
    "    \n",
    "    return xgb_search.best_estimator_, gb_search.best_estimator_\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume X_train, X_test, y_train, y_test are your data\n",
    "    \n",
    "    # Option 1: Quick training with default parameters\n",
    "    models = improve_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Option 2: Training with hyperparameter tuning\n",
    "    # First tune the models\n",
    "    best_xgb, best_gb = tune_models(X_train, y_train)\n",
    "    \n",
    "    # Then use the best models in your ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.7344   \u001b[39m | \u001b[39m0.7498   \u001b[39m | \u001b[39m0.4754   \u001b[39m | \u001b[39m0.2223   \u001b[39m | \u001b[39m7.191    \u001b[39m | \u001b[39m2.404    \u001b[39m | \u001b[39m162.4    \u001b[39m | \u001b[39m0.6232   \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.7374   \u001b[39m | \u001b[35m0.9465   \u001b[39m | \u001b[35m0.3006   \u001b[39m | \u001b[35m0.2153   \u001b[39m | \u001b[35m3.144    \u001b[39m | \u001b[35m9.729    \u001b[39m | \u001b[35m433.0    \u001b[39m | \u001b[35m0.6849   \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.7367   \u001b[39m | \u001b[39m0.6727   \u001b[39m | \u001b[39m0.0917   \u001b[39m | \u001b[39m0.09823  \u001b[39m | \u001b[39m6.673    \u001b[39m | \u001b[39m4.888    \u001b[39m | \u001b[39m216.5    \u001b[39m | \u001b[39m0.8447   \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.7371   \u001b[39m | \u001b[39m0.6558   \u001b[39m | \u001b[39m0.1461   \u001b[39m | \u001b[39m0.1162   \u001b[39m | \u001b[39m6.192    \u001b[39m | \u001b[39m8.067    \u001b[39m | \u001b[39m179.9    \u001b[39m | \u001b[39m0.8057   \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.7361   \u001b[39m | \u001b[39m0.837    \u001b[39m | \u001b[39m0.02323  \u001b[39m | \u001b[39m0.1862   \u001b[39m | \u001b[39m4.194    \u001b[39m | \u001b[39m1.585    \u001b[39m | \u001b[39m479.6    \u001b[39m | \u001b[39m0.9863   \u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m0.7374   \u001b[39m | \u001b[35m0.9234   \u001b[39m | \u001b[35m0.1523   \u001b[39m | \u001b[35m0.03832  \u001b[39m | \u001b[35m7.79     \u001b[39m | \u001b[35m4.961    \u001b[39m | \u001b[35m148.8    \u001b[39m | \u001b[35m0.7981   \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7366   \u001b[39m | \u001b[39m0.6138   \u001b[39m | \u001b[39m0.4547   \u001b[39m | \u001b[39m0.08505  \u001b[39m | \u001b[39m7.638    \u001b[39m | \u001b[39m3.805    \u001b[39m | \u001b[39m308.0    \u001b[39m | \u001b[39m0.8187   \u001b[39m |\n",
      "| \u001b[35m8        \u001b[39m | \u001b[35m0.7378   \u001b[39m | \u001b[35m0.6739   \u001b[39m | \u001b[35m0.4848   \u001b[39m | \u001b[35m0.2348   \u001b[39m | \u001b[35m9.576    \u001b[39m | \u001b[35m9.053    \u001b[39m | \u001b[35m339.2    \u001b[39m | \u001b[35m0.9687   \u001b[39m |\n",
      "| \u001b[35m9        \u001b[39m | \u001b[35m0.7393   \u001b[39m | \u001b[35m0.6354   \u001b[39m | \u001b[35m0.09799  \u001b[39m | \u001b[35m0.02312  \u001b[39m | \u001b[35m5.277    \u001b[39m | \u001b[35m4.498    \u001b[39m | \u001b[35m208.5    \u001b[39m | \u001b[35m0.9315   \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.7427   \u001b[39m | \u001b[39m0.1405   \u001b[39m | \u001b[39m0.1674   \u001b[39m | \u001b[39m3.986    \u001b[39m | \u001b[39m8.22     \u001b[39m | \u001b[39m129.8    \u001b[39m | \u001b[39m0.9948   \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.7367   \u001b[39m | \u001b[39m0.8257   \u001b[39m | \u001b[39m0.2584   \u001b[39m | \u001b[39m0.2187   \u001b[39m | \u001b[39m4.23     \u001b[39m | \u001b[39m8.669    \u001b[39m | \u001b[39m129.6    \u001b[39m | \u001b[39m0.8412   \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.7297   \u001b[39m | \u001b[39m0.6257   \u001b[39m | \u001b[39m0.05448  \u001b[39m | \u001b[39m0.27     \u001b[39m | \u001b[39m8.95     \u001b[39m | \u001b[39m7.767    \u001b[39m | \u001b[39m211.6    \u001b[39m | \u001b[39m0.7991   \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.7382   \u001b[39m | \u001b[39m0.9579   \u001b[39m | \u001b[39m0.4788   \u001b[39m | \u001b[39m0.1792   \u001b[39m | \u001b[39m4.406    \u001b[39m | \u001b[39m8.12     \u001b[39m | \u001b[39m129.8    \u001b[39m | \u001b[39m0.8818   \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.7383   \u001b[39m | \u001b[39m0.6794   \u001b[39m | \u001b[39m0.1891   \u001b[39m | \u001b[39m0.08628  \u001b[39m | \u001b[39m4.005    \u001b[39m | \u001b[39m7.119    \u001b[39m | \u001b[39m130.2    \u001b[39m | \u001b[39m0.6202   \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.7382   \u001b[39m | \u001b[39m0.9437   \u001b[39m | \u001b[39m0.06977  \u001b[39m | \u001b[39m0.09589  \u001b[39m | \u001b[39m5.85     \u001b[39m | \u001b[39m4.456    \u001b[39m | \u001b[39m209.5    \u001b[39m | \u001b[39m0.9901   \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.7321   \u001b[39m | \u001b[39m0.8662   \u001b[39m | \u001b[39m0.2432   \u001b[39m | \u001b[39m0.2886   \u001b[39m | \u001b[39m6.355    \u001b[39m | \u001b[39m3.951    \u001b[39m | \u001b[39m208.1    \u001b[39m | \u001b[39m0.7093   \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.7378   \u001b[39m | \u001b[39m0.7997   \u001b[39m | \u001b[39m0.4535   \u001b[39m | \u001b[39m0.08662  \u001b[39m | \u001b[39m5.062    \u001b[39m | \u001b[39m4.432    \u001b[39m | \u001b[39m209.5    \u001b[39m | \u001b[39m0.6954   \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.7383   \u001b[39m | \u001b[39m0.9234   \u001b[39m | \u001b[39m0.09364  \u001b[39m | \u001b[39m0.172    \u001b[39m | \u001b[39m4.552    \u001b[39m | \u001b[39m8.258    \u001b[39m | \u001b[39m131.0    \u001b[39m | \u001b[39m0.9799   \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.738    \u001b[39m | \u001b[39m0.759    \u001b[39m | \u001b[39m0.4866   \u001b[39m | \u001b[39m0.09757  \u001b[39m | \u001b[39m4.706    \u001b[39m | \u001b[39m5.235    \u001b[39m | \u001b[39m208.1    \u001b[39m | \u001b[39m0.6109   \u001b[39m |\n",
      "| \u001b[35m20       \u001b[39m | \u001b[35m0.7393   \u001b[39m | \u001b[35m0.9229   \u001b[39m | \u001b[35m0.3131   \u001b[39m | \u001b[35m0.1381   \u001b[39m | \u001b[35m3.071    \u001b[39m | \u001b[35m7.008    \u001b[39m | \u001b[35m131.4    \u001b[39m | \u001b[35m0.9681   \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.7386   \u001b[39m | \u001b[39m0.9614   \u001b[39m | \u001b[39m0.1928   \u001b[39m | \u001b[39m0.1952   \u001b[39m | \u001b[39m3.506    \u001b[39m | \u001b[39m8.177    \u001b[39m | \u001b[39m130.9    \u001b[39m | \u001b[39m0.8383   \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.6431   \u001b[39m | \u001b[39m0.1529   \u001b[39m | \u001b[39m0.1177   \u001b[39m | \u001b[39m3.035    \u001b[39m | \u001b[39m7.172    \u001b[39m | \u001b[39m132.4    \u001b[39m | \u001b[39m0.6268   \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.6004   \u001b[39m | \u001b[39m0.06934  \u001b[39m | \u001b[39m0.07059  \u001b[39m | \u001b[39m3.998    \u001b[39m | \u001b[39m6.081    \u001b[39m | \u001b[39m132.3    \u001b[39m | \u001b[39m0.9959   \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.7389   \u001b[39m | \u001b[39m0.6277   \u001b[39m | \u001b[39m0.4237   \u001b[39m | \u001b[39m0.06951  \u001b[39m | \u001b[39m3.555    \u001b[39m | \u001b[39m8.471    \u001b[39m | \u001b[39m133.0    \u001b[39m | \u001b[39m0.9661   \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.7511   \u001b[39m | \u001b[39m0.3467   \u001b[39m | \u001b[39m0.07306  \u001b[39m | \u001b[39m4.26     \u001b[39m | \u001b[39m6.59     \u001b[39m | \u001b[39m133.8    \u001b[39m | \u001b[39m0.9915   \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.7368   \u001b[39m | \u001b[39m0.7213   \u001b[39m | \u001b[39m0.3757   \u001b[39m | \u001b[39m0.2713   \u001b[39m | \u001b[39m5.378    \u001b[39m | \u001b[39m7.302    \u001b[39m | \u001b[39m132.6    \u001b[39m | \u001b[39m0.6446   \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.831    \u001b[39m | \u001b[39m0.09878  \u001b[39m | \u001b[39m0.1782   \u001b[39m | \u001b[39m3.258    \u001b[39m | \u001b[39m6.701    \u001b[39m | \u001b[39m134.7    \u001b[39m | \u001b[39m0.8934   \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.7379   \u001b[39m | \u001b[39m0.972    \u001b[39m | \u001b[39m0.07562  \u001b[39m | \u001b[39m0.2121   \u001b[39m | \u001b[39m4.372    \u001b[39m | \u001b[39m8.087    \u001b[39m | \u001b[39m134.1    \u001b[39m | \u001b[39m0.7522   \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.8062   \u001b[39m | \u001b[39m0.09507  \u001b[39m | \u001b[39m0.1417   \u001b[39m | \u001b[39m3.772    \u001b[39m | \u001b[39m5.651    \u001b[39m | \u001b[39m133.8    \u001b[39m | \u001b[39m0.9888   \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m0.7376   \u001b[39m | \u001b[39m0.7942   \u001b[39m | \u001b[39m0.4202   \u001b[39m | \u001b[39m0.208    \u001b[39m | \u001b[39m5.179    \u001b[39m | \u001b[39m5.323    \u001b[39m | \u001b[39m135.3    \u001b[39m | \u001b[39m0.8591   \u001b[39m |\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.7006   \u001b[39m | \u001b[39m0.3527   \u001b[39m | \u001b[39m0.2144   \u001b[39m | \u001b[39m3.268    \u001b[39m | \u001b[39m4.937    \u001b[39m | \u001b[39m132.9    \u001b[39m | \u001b[39m0.7224   \u001b[39m |\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.8007   \u001b[39m | \u001b[39m0.4793   \u001b[39m | \u001b[39m0.1433   \u001b[39m | \u001b[39m3.158    \u001b[39m | \u001b[39m4.33     \u001b[39m | \u001b[39m131.2    \u001b[39m | \u001b[39m0.695    \u001b[39m |\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m0.7382   \u001b[39m | \u001b[39m0.8268   \u001b[39m | \u001b[39m0.1134   \u001b[39m | \u001b[39m0.2933   \u001b[39m | \u001b[39m3.393    \u001b[39m | \u001b[39m5.659    \u001b[39m | \u001b[39m130.8    \u001b[39m | \u001b[39m0.7221   \u001b[39m |\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m0.7341   \u001b[39m | \u001b[39m0.6824   \u001b[39m | \u001b[39m0.07961  \u001b[39m | \u001b[39m0.01546  \u001b[39m | \u001b[39m3.17     \u001b[39m | \u001b[39m3.345    \u001b[39m | \u001b[39m132.4    \u001b[39m | \u001b[39m0.8719   \u001b[39m |\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.6762   \u001b[39m | \u001b[39m0.4266   \u001b[39m | \u001b[39m0.231    \u001b[39m | \u001b[39m3.092    \u001b[39m | \u001b[39m3.93     \u001b[39m | \u001b[39m129.6    \u001b[39m | \u001b[39m0.7932   \u001b[39m |\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m0.7386   \u001b[39m | \u001b[39m0.7819   \u001b[39m | \u001b[39m0.4592   \u001b[39m | \u001b[39m0.1721   \u001b[39m | \u001b[39m4.924    \u001b[39m | \u001b[39m4.83     \u001b[39m | \u001b[39m132.8    \u001b[39m | \u001b[39m0.8184   \u001b[39m |\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m0.7384   \u001b[39m | \u001b[39m0.6589   \u001b[39m | \u001b[39m0.3185   \u001b[39m | \u001b[39m0.1756   \u001b[39m | \u001b[39m4.891    \u001b[39m | \u001b[39m4.228    \u001b[39m | \u001b[39m130.4    \u001b[39m | \u001b[39m0.7277   \u001b[39m |\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.7224   \u001b[39m | \u001b[39m0.2262   \u001b[39m | \u001b[39m0.07778  \u001b[39m | \u001b[39m3.749    \u001b[39m | \u001b[39m3.909    \u001b[39m | \u001b[39m208.7    \u001b[39m | \u001b[39m0.6876   \u001b[39m |\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.7564   \u001b[39m | \u001b[39m0.3405   \u001b[39m | \u001b[39m0.2242   \u001b[39m | \u001b[39m3.01     \u001b[39m | \u001b[39m7.109    \u001b[39m | \u001b[39m133.4    \u001b[39m | \u001b[39m0.8533   \u001b[39m |\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m0.7389   \u001b[39m | \u001b[39m0.6556   \u001b[39m | \u001b[39m0.06852  \u001b[39m | \u001b[39m0.03713  \u001b[39m | \u001b[39m3.11     \u001b[39m | \u001b[39m1.85     \u001b[39m | \u001b[39m208.2    \u001b[39m | \u001b[39m0.8951   \u001b[39m |\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.7049   \u001b[39m | \u001b[39m0.4109   \u001b[39m | \u001b[39m0.1272   \u001b[39m | \u001b[39m3.363    \u001b[39m | \u001b[39m2.846    \u001b[39m | \u001b[39m209.4    \u001b[39m | \u001b[39m0.7925   \u001b[39m |\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m0.7387   \u001b[39m | \u001b[39m0.7648   \u001b[39m | \u001b[39m0.1436   \u001b[39m | \u001b[39m0.2657   \u001b[39m | \u001b[39m3.73     \u001b[39m | \u001b[39m1.475    \u001b[39m | \u001b[39m210.6    \u001b[39m | \u001b[39m0.9735   \u001b[39m |\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m0.7385   \u001b[39m | \u001b[39m0.869    \u001b[39m | \u001b[39m0.05632  \u001b[39m | \u001b[39m0.1653   \u001b[39m | \u001b[39m3.933    \u001b[39m | \u001b[39m2.995    \u001b[39m | \u001b[39m207.1    \u001b[39m | \u001b[39m0.6844   \u001b[39m |\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m0.7366   \u001b[39m | \u001b[39m0.799    \u001b[39m | \u001b[39m0.2001   \u001b[39m | \u001b[39m0.1935   \u001b[39m | \u001b[39m4.466    \u001b[39m | \u001b[39m2.132    \u001b[39m | \u001b[39m208.6    \u001b[39m | \u001b[39m0.8389   \u001b[39m |\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.8431   \u001b[39m | \u001b[39m0.4601   \u001b[39m | \u001b[39m0.1003   \u001b[39m | \u001b[39m3.118    \u001b[39m | \u001b[39m3.663    \u001b[39m | \u001b[39m208.0    \u001b[39m | \u001b[39m0.8918   \u001b[39m |\n",
      "| \u001b[35m46       \u001b[39m | \u001b[35m0.7397   \u001b[39m | \u001b[35m0.8309   \u001b[39m | \u001b[35m0.1932   \u001b[39m | \u001b[35m0.08525  \u001b[39m | \u001b[35m3.149    \u001b[39m | \u001b[35m2.426    \u001b[39m | \u001b[35m212.0    \u001b[39m | \u001b[35m0.8109   \u001b[39m |\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.9113   \u001b[39m | \u001b[39m0.01126  \u001b[39m | \u001b[39m0.08878  \u001b[39m | \u001b[39m3.033    \u001b[39m | \u001b[39m3.724    \u001b[39m | \u001b[39m211.6    \u001b[39m | \u001b[39m0.765    \u001b[39m |\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m0.737    \u001b[39m | \u001b[39m0.8665   \u001b[39m | \u001b[39m0.1534   \u001b[39m | \u001b[39m0.01487  \u001b[39m | \u001b[39m4.482    \u001b[39m | \u001b[39m2.665    \u001b[39m | \u001b[39m211.2    \u001b[39m | \u001b[39m0.845    \u001b[39m |\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m0.7384   \u001b[39m | \u001b[39m0.9439   \u001b[39m | \u001b[39m0.05097  \u001b[39m | \u001b[39m0.2621   \u001b[39m | \u001b[39m3.098    \u001b[39m | \u001b[39m4.066    \u001b[39m | \u001b[39m213.0    \u001b[39m | \u001b[39m0.8218   \u001b[39m |\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m0.7387   \u001b[39m | \u001b[39m0.8531   \u001b[39m | \u001b[39m0.3228   \u001b[39m | \u001b[39m0.2318   \u001b[39m | \u001b[39m3.571    \u001b[39m | \u001b[39m2.021    \u001b[39m | \u001b[39m213.5    \u001b[39m | \u001b[39m0.9997   \u001b[39m |\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m0.7383   \u001b[39m | \u001b[39m0.8128   \u001b[39m | \u001b[39m0.04613  \u001b[39m | \u001b[39m0.2008   \u001b[39m | \u001b[39m3.013    \u001b[39m | \u001b[39m4.81     \u001b[39m | \u001b[39m206.7    \u001b[39m | \u001b[39m0.9777   \u001b[39m |\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m0.7386   \u001b[39m | \u001b[39m0.6734   \u001b[39m | \u001b[39m0.3508   \u001b[39m | \u001b[39m0.251    \u001b[39m | \u001b[39m3.18     \u001b[39m | \u001b[39m5.624    \u001b[39m | \u001b[39m212.1    \u001b[39m | \u001b[39m0.9491   \u001b[39m |\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.6831   \u001b[39m | \u001b[39m0.2408   \u001b[39m | \u001b[39m0.1359   \u001b[39m | \u001b[39m3.294    \u001b[39m | \u001b[39m1.185    \u001b[39m | \u001b[39m206.7    \u001b[39m | \u001b[39m0.9458   \u001b[39m |\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m0.7381   \u001b[39m | \u001b[39m0.7289   \u001b[39m | \u001b[39m0.396    \u001b[39m | \u001b[39m0.1455   \u001b[39m | \u001b[39m4.806    \u001b[39m | \u001b[39m1.696    \u001b[39m | \u001b[39m205.4    \u001b[39m | \u001b[39m0.6665   \u001b[39m |\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m0.7386   \u001b[39m | \u001b[39m0.616    \u001b[39m | \u001b[39m0.2811   \u001b[39m | \u001b[39m0.2102   \u001b[39m | \u001b[39m3.254    \u001b[39m | \u001b[39m4.636    \u001b[39m | \u001b[39m211.1    \u001b[39m | \u001b[39m0.9112   \u001b[39m |\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m0.7381   \u001b[39m | \u001b[39m0.9553   \u001b[39m | \u001b[39m0.1861   \u001b[39m | \u001b[39m0.2995   \u001b[39m | \u001b[39m3.287    \u001b[39m | \u001b[39m1.284    \u001b[39m | \u001b[39m212.8    \u001b[39m | \u001b[39m0.6299   \u001b[39m |\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.9369   \u001b[39m | \u001b[39m0.3486   \u001b[39m | \u001b[39m0.2443   \u001b[39m | \u001b[39m3.031    \u001b[39m | \u001b[39m4.137    \u001b[39m | \u001b[39m210.0    \u001b[39m | \u001b[39m0.9763   \u001b[39m |\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.8061   \u001b[39m | \u001b[39m0.0213   \u001b[39m | \u001b[39m0.07188  \u001b[39m | \u001b[39m3.155    \u001b[39m | \u001b[39m1.792    \u001b[39m | \u001b[39m205.8    \u001b[39m | \u001b[39m0.8707   \u001b[39m |\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m0.738    \u001b[39m | \u001b[39m0.8946   \u001b[39m | \u001b[39m0.08241  \u001b[39m | \u001b[39m0.02955  \u001b[39m | \u001b[39m3.311    \u001b[39m | \u001b[39m1.862    \u001b[39m | \u001b[39m204.1    \u001b[39m | \u001b[39m0.7357   \u001b[39m |\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m0.7381   \u001b[39m | \u001b[39m0.7009   \u001b[39m | \u001b[39m0.4042   \u001b[39m | \u001b[39m0.2448   \u001b[39m | \u001b[39m3.09     \u001b[39m | \u001b[39m7.52     \u001b[39m | \u001b[39m128.6    \u001b[39m | \u001b[39m0.6799   \u001b[39m |\n",
      "| \u001b[39m61       \u001b[39m | \u001b[39m0.7378   \u001b[39m | \u001b[39m0.7146   \u001b[39m | \u001b[39m0.2985   \u001b[39m | \u001b[39m0.02765  \u001b[39m | \u001b[39m3.274    \u001b[39m | \u001b[39m6.026    \u001b[39m | \u001b[39m209.9    \u001b[39m | \u001b[39m0.7914   \u001b[39m |\n",
      "| \u001b[39m62       \u001b[39m | \u001b[39m0.7381   \u001b[39m | \u001b[39m0.9323   \u001b[39m | \u001b[39m0.346    \u001b[39m | \u001b[39m0.05083  \u001b[39m | \u001b[39m3.005    \u001b[39m | \u001b[39m6.136    \u001b[39m | \u001b[39m132.3    \u001b[39m | \u001b[39m0.9851   \u001b[39m |\n",
      "| \u001b[39m63       \u001b[39m | \u001b[39m0.7385   \u001b[39m | \u001b[39m0.8142   \u001b[39m | \u001b[39m0.002944 \u001b[39m | \u001b[39m0.2011   \u001b[39m | \u001b[39m3.139    \u001b[39m | \u001b[39m3.951    \u001b[39m | \u001b[39m204.8    \u001b[39m | \u001b[39m0.7833   \u001b[39m |\n",
      "| \u001b[39m64       \u001b[39m | \u001b[39m0.7383   \u001b[39m | \u001b[39m0.6328   \u001b[39m | \u001b[39m0.4638   \u001b[39m | \u001b[39m0.1911   \u001b[39m | \u001b[39m4.469    \u001b[39m | \u001b[39m2.975    \u001b[39m | \u001b[39m128.5    \u001b[39m | \u001b[39m0.6573   \u001b[39m |\n",
      "| \u001b[39m65       \u001b[39m | \u001b[39m0.7387   \u001b[39m | \u001b[39m0.8535   \u001b[39m | \u001b[39m0.3271   \u001b[39m | \u001b[39m0.1806   \u001b[39m | \u001b[39m3.075    \u001b[39m | \u001b[39m9.929    \u001b[39m | \u001b[39m133.1    \u001b[39m | \u001b[39m0.6637   \u001b[39m |\n",
      "| \u001b[39m66       \u001b[39m | \u001b[39m0.7383   \u001b[39m | \u001b[39m0.662    \u001b[39m | \u001b[39m0.1015   \u001b[39m | \u001b[39m0.2554   \u001b[39m | \u001b[39m3.004    \u001b[39m | \u001b[39m1.918    \u001b[39m | \u001b[39m207.0    \u001b[39m | \u001b[39m0.7553   \u001b[39m |\n",
      "| \u001b[39m67       \u001b[39m | \u001b[39m0.7381   \u001b[39m | \u001b[39m0.6855   \u001b[39m | \u001b[39m0.4268   \u001b[39m | \u001b[39m0.2497   \u001b[39m | \u001b[39m4.484    \u001b[39m | \u001b[39m3.202    \u001b[39m | \u001b[39m214.3    \u001b[39m | \u001b[39m0.9442   \u001b[39m |\n",
      "| \u001b[39m68       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.8661   \u001b[39m | \u001b[39m0.3718   \u001b[39m | \u001b[39m0.2611   \u001b[39m | \u001b[39m3.995    \u001b[39m | \u001b[39m5.716    \u001b[39m | \u001b[39m213.6    \u001b[39m | \u001b[39m0.9525   \u001b[39m |\n",
      "| \u001b[39m69       \u001b[39m | \u001b[39m0.7381   \u001b[39m | \u001b[39m0.9397   \u001b[39m | \u001b[39m0.1639   \u001b[39m | \u001b[39m0.2496   \u001b[39m | \u001b[39m3.047    \u001b[39m | \u001b[39m2.306    \u001b[39m | \u001b[39m210.7    \u001b[39m | \u001b[39m0.8629   \u001b[39m |\n",
      "| \u001b[39m70       \u001b[39m | \u001b[39m0.7389   \u001b[39m | \u001b[39m0.6877   \u001b[39m | \u001b[39m0.4705   \u001b[39m | \u001b[39m0.2004   \u001b[39m | \u001b[39m3.712    \u001b[39m | \u001b[39m6.347    \u001b[39m | \u001b[39m214.8    \u001b[39m | \u001b[39m0.9722   \u001b[39m |\n",
      "| \u001b[39m71       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.8957   \u001b[39m | \u001b[39m0.4589   \u001b[39m | \u001b[39m0.08599  \u001b[39m | \u001b[39m3.348    \u001b[39m | \u001b[39m7.643    \u001b[39m | \u001b[39m213.8    \u001b[39m | \u001b[39m0.9343   \u001b[39m |\n",
      "| \u001b[39m72       \u001b[39m | \u001b[39m0.7371   \u001b[39m | \u001b[39m0.9737   \u001b[39m | \u001b[39m0.1167   \u001b[39m | \u001b[39m0.2269   \u001b[39m | \u001b[39m4.272    \u001b[39m | \u001b[39m7.252    \u001b[39m | \u001b[39m214.4    \u001b[39m | \u001b[39m0.8824   \u001b[39m |\n",
      "| \u001b[39m73       \u001b[39m | \u001b[39m0.7379   \u001b[39m | \u001b[39m0.8716   \u001b[39m | \u001b[39m0.1486   \u001b[39m | \u001b[39m0.141    \u001b[39m | \u001b[39m4.094    \u001b[39m | \u001b[39m5.094    \u001b[39m | \u001b[39m214.9    \u001b[39m | \u001b[39m0.6827   \u001b[39m |\n",
      "| \u001b[39m74       \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.6014   \u001b[39m | \u001b[39m0.4856   \u001b[39m | \u001b[39m0.2451   \u001b[39m | \u001b[39m3.323    \u001b[39m | \u001b[39m7.895    \u001b[39m | \u001b[39m212.5    \u001b[39m | \u001b[39m0.7245   \u001b[39m |\n",
      "| \u001b[39m75       \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.9987   \u001b[39m | \u001b[39m0.1017   \u001b[39m | \u001b[39m0.2399   \u001b[39m | \u001b[39m3.164    \u001b[39m | \u001b[39m7.878    \u001b[39m | \u001b[39m130.1    \u001b[39m | \u001b[39m0.9888   \u001b[39m |\n",
      "| \u001b[39m76       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.9607   \u001b[39m | \u001b[39m0.29     \u001b[39m | \u001b[39m0.03712  \u001b[39m | \u001b[39m4.628    \u001b[39m | \u001b[39m6.748    \u001b[39m | \u001b[39m212.2    \u001b[39m | \u001b[39m0.9102   \u001b[39m |\n",
      "| \u001b[39m77       \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.8371   \u001b[39m | \u001b[39m0.4847   \u001b[39m | \u001b[39m0.08776  \u001b[39m | \u001b[39m3.023    \u001b[39m | \u001b[39m6.167    \u001b[39m | \u001b[39m214.0    \u001b[39m | \u001b[39m0.956    \u001b[39m |\n",
      "| \u001b[39m78       \u001b[39m | \u001b[39m0.7334   \u001b[39m | \u001b[39m0.9306   \u001b[39m | \u001b[39m0.1767   \u001b[39m | \u001b[39m0.2119   \u001b[39m | \u001b[39m6.081    \u001b[39m | \u001b[39m5.989    \u001b[39m | \u001b[39m212.5    \u001b[39m | \u001b[39m0.8646   \u001b[39m |\n",
      "| \u001b[39m79       \u001b[39m | \u001b[39m0.7386   \u001b[39m | \u001b[39m0.6671   \u001b[39m | \u001b[39m0.1048   \u001b[39m | \u001b[39m0.1205   \u001b[39m | \u001b[39m4.756    \u001b[39m | \u001b[39m8.377    \u001b[39m | \u001b[39m212.2    \u001b[39m | \u001b[39m0.7893   \u001b[39m |\n",
      "| \u001b[39m80       \u001b[39m | \u001b[39m0.7382   \u001b[39m | \u001b[39m0.6354   \u001b[39m | \u001b[39m0.3648   \u001b[39m | \u001b[39m0.1765   \u001b[39m | \u001b[39m3.49     \u001b[39m | \u001b[39m6.725    \u001b[39m | \u001b[39m211.8    \u001b[39m | \u001b[39m0.7085   \u001b[39m |\n",
      "| \u001b[35m81       \u001b[39m | \u001b[35m0.7397   \u001b[39m | \u001b[35m0.9748   \u001b[39m | \u001b[35m0.05138  \u001b[39m | \u001b[35m0.0492   \u001b[39m | \u001b[35m3.238    \u001b[39m | \u001b[35m9.45     \u001b[39m | \u001b[35m213.4    \u001b[39m | \u001b[35m0.6054   \u001b[39m |\n",
      "| \u001b[39m82       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.6257   \u001b[39m | \u001b[39m0.1988   \u001b[39m | \u001b[39m0.06606  \u001b[39m | \u001b[39m3.616    \u001b[39m | \u001b[39m9.844    \u001b[39m | \u001b[39m214.9    \u001b[39m | \u001b[39m0.6409   \u001b[39m |\n",
      "| \u001b[39m83       \u001b[39m | \u001b[39m0.7385   \u001b[39m | \u001b[39m0.6558   \u001b[39m | \u001b[39m0.01459  \u001b[39m | \u001b[39m0.05753  \u001b[39m | \u001b[39m3.134    \u001b[39m | \u001b[39m8.662    \u001b[39m | \u001b[39m215.1    \u001b[39m | \u001b[39m0.7532   \u001b[39m |\n",
      "| \u001b[39m84       \u001b[39m | \u001b[39m0.7384   \u001b[39m | \u001b[39m0.9698   \u001b[39m | \u001b[39m0.1407   \u001b[39m | \u001b[39m0.1954   \u001b[39m | \u001b[39m3.265    \u001b[39m | \u001b[39m8.426    \u001b[39m | \u001b[39m213.5    \u001b[39m | \u001b[39m0.8543   \u001b[39m |\n",
      "| \u001b[39m85       \u001b[39m | \u001b[39m0.7363   \u001b[39m | \u001b[39m0.7987   \u001b[39m | \u001b[39m0.2396   \u001b[39m | \u001b[39m0.1577   \u001b[39m | \u001b[39m5.229    \u001b[39m | \u001b[39m9.432    \u001b[39m | \u001b[39m214.0    \u001b[39m | \u001b[39m0.7376   \u001b[39m |\n",
      "| \u001b[39m86       \u001b[39m | \u001b[39m0.7382   \u001b[39m | \u001b[39m0.843    \u001b[39m | \u001b[39m0.01881  \u001b[39m | \u001b[39m0.2441   \u001b[39m | \u001b[39m3.734    \u001b[39m | \u001b[39m9.107    \u001b[39m | \u001b[39m210.8    \u001b[39m | \u001b[39m0.9091   \u001b[39m |\n",
      "| \u001b[39m87       \u001b[39m | \u001b[39m0.7382   \u001b[39m | \u001b[39m0.9183   \u001b[39m | \u001b[39m0.07423  \u001b[39m | \u001b[39m0.2677   \u001b[39m | \u001b[39m3.166    \u001b[39m | \u001b[39m2.969    \u001b[39m | \u001b[39m212.7    \u001b[39m | \u001b[39m0.6573   \u001b[39m |\n",
      "| \u001b[39m88       \u001b[39m | \u001b[39m0.7379   \u001b[39m | \u001b[39m0.8094   \u001b[39m | \u001b[39m0.1583   \u001b[39m | \u001b[39m0.1587   \u001b[39m | \u001b[39m4.834    \u001b[39m | \u001b[39m7.342    \u001b[39m | \u001b[39m211.3    \u001b[39m | \u001b[39m0.922    \u001b[39m |\n",
      "| \u001b[39m89       \u001b[39m | \u001b[39m0.7385   \u001b[39m | \u001b[39m0.8887   \u001b[39m | \u001b[39m0.09695  \u001b[39m | \u001b[39m0.179    \u001b[39m | \u001b[39m3.111    \u001b[39m | \u001b[39m4.316    \u001b[39m | \u001b[39m208.9    \u001b[39m | \u001b[39m0.9902   \u001b[39m |\n",
      "| \u001b[39m90       \u001b[39m | \u001b[39m0.7381   \u001b[39m | \u001b[39m0.8911   \u001b[39m | \u001b[39m0.2859   \u001b[39m | \u001b[39m0.2304   \u001b[39m | \u001b[39m4.358    \u001b[39m | \u001b[39m9.983    \u001b[39m | \u001b[39m216.7    \u001b[39m | \u001b[39m0.9568   \u001b[39m |\n",
      "| \u001b[39m91       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.8132   \u001b[39m | \u001b[39m0.4449   \u001b[39m | \u001b[39m0.04103  \u001b[39m | \u001b[39m3.974    \u001b[39m | \u001b[39m1.079    \u001b[39m | \u001b[39m206.5    \u001b[39m | \u001b[39m0.7005   \u001b[39m |\n",
      "| \u001b[39m92       \u001b[39m | \u001b[39m0.7387   \u001b[39m | \u001b[39m0.9233   \u001b[39m | \u001b[39m0.09122  \u001b[39m | \u001b[39m0.2823   \u001b[39m | \u001b[39m3.292    \u001b[39m | \u001b[39m1.02     \u001b[39m | \u001b[39m205.6    \u001b[39m | \u001b[39m0.9999   \u001b[39m |\n",
      "| \u001b[39m93       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.9874   \u001b[39m | \u001b[39m0.3138   \u001b[39m | \u001b[39m0.1695   \u001b[39m | \u001b[39m3.108    \u001b[39m | \u001b[39m2.946    \u001b[39m | \u001b[39m206.0    \u001b[39m | \u001b[39m0.9504   \u001b[39m |\n",
      "| \u001b[39m94       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.776    \u001b[39m | \u001b[39m0.04949  \u001b[39m | \u001b[39m0.08509  \u001b[39m | \u001b[39m3.356    \u001b[39m | \u001b[39m9.576    \u001b[39m | \u001b[39m212.4    \u001b[39m | \u001b[39m0.6958   \u001b[39m |\n",
      "| \u001b[39m95       \u001b[39m | \u001b[39m0.7382   \u001b[39m | \u001b[39m0.808    \u001b[39m | \u001b[39m0.2778   \u001b[39m | \u001b[39m0.1397   \u001b[39m | \u001b[39m4.282    \u001b[39m | \u001b[39m1.184    \u001b[39m | \u001b[39m215.1    \u001b[39m | \u001b[39m0.7521   \u001b[39m |\n",
      "| \u001b[39m96       \u001b[39m | \u001b[39m0.7381   \u001b[39m | \u001b[39m0.9271   \u001b[39m | \u001b[39m0.07184  \u001b[39m | \u001b[39m0.2908   \u001b[39m | \u001b[39m3.707    \u001b[39m | \u001b[39m6.699    \u001b[39m | \u001b[39m212.8    \u001b[39m | \u001b[39m0.9185   \u001b[39m |\n",
      "| \u001b[39m97       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.7096   \u001b[39m | \u001b[39m0.02626  \u001b[39m | \u001b[39m0.1337   \u001b[39m | \u001b[39m3.1      \u001b[39m | \u001b[39m9.823    \u001b[39m | \u001b[39m213.9    \u001b[39m | \u001b[39m0.6477   \u001b[39m |\n",
      "| \u001b[39m98       \u001b[39m | \u001b[39m0.7385   \u001b[39m | \u001b[39m0.7939   \u001b[39m | \u001b[39m0.3917   \u001b[39m | \u001b[39m0.2431   \u001b[39m | \u001b[39m3.911    \u001b[39m | \u001b[39m5.097    \u001b[39m | \u001b[39m127.5    \u001b[39m | \u001b[39m0.6607   \u001b[39m |\n",
      "| \u001b[39m99       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.8055   \u001b[39m | \u001b[39m0.01379  \u001b[39m | \u001b[39m0.07266  \u001b[39m | \u001b[39m4.138    \u001b[39m | \u001b[39m4.544    \u001b[39m | \u001b[39m125.7    \u001b[39m | \u001b[39m0.9005   \u001b[39m |\n",
      "| \u001b[39m100      \u001b[39m | \u001b[39m0.7375   \u001b[39m | \u001b[39m0.6367   \u001b[39m | \u001b[39m0.3376   \u001b[39m | \u001b[39m0.25     \u001b[39m | \u001b[39m5.161    \u001b[39m | \u001b[39m5.425    \u001b[39m | \u001b[39m125.4    \u001b[39m | \u001b[39m0.7382   \u001b[39m |\n",
      "| \u001b[39m101      \u001b[39m | \u001b[39m0.7364   \u001b[39m | \u001b[39m0.9417   \u001b[39m | \u001b[39m0.2342   \u001b[39m | \u001b[39m0.02981  \u001b[39m | \u001b[39m3.508    \u001b[39m | \u001b[39m3.922    \u001b[39m | \u001b[39m126.8    \u001b[39m | \u001b[39m0.8018   \u001b[39m |\n",
      "| \u001b[39m102      \u001b[39m | \u001b[39m0.7366   \u001b[39m | \u001b[39m0.7549   \u001b[39m | \u001b[39m0.2359   \u001b[39m | \u001b[39m0.03272  \u001b[39m | \u001b[39m3.104    \u001b[39m | \u001b[39m5.424    \u001b[39m | \u001b[39m125.2    \u001b[39m | \u001b[39m0.9056   \u001b[39m |\n",
      "| \u001b[39m103      \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.6664   \u001b[39m | \u001b[39m0.02407  \u001b[39m | \u001b[39m0.1218   \u001b[39m | \u001b[39m3.069    \u001b[39m | \u001b[39m5.069    \u001b[39m | \u001b[39m135.0    \u001b[39m | \u001b[39m0.953    \u001b[39m |\n",
      "| \u001b[39m104      \u001b[39m | \u001b[39m0.7365   \u001b[39m | \u001b[39m0.8192   \u001b[39m | \u001b[39m0.3873   \u001b[39m | \u001b[39m0.01933  \u001b[39m | \u001b[39m3.615    \u001b[39m | \u001b[39m9.88     \u001b[39m | \u001b[39m213.2    \u001b[39m | \u001b[39m0.7213   \u001b[39m |\n",
      "| \u001b[39m105      \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.7303   \u001b[39m | \u001b[39m0.2038   \u001b[39m | \u001b[39m0.1383   \u001b[39m | \u001b[39m3.574    \u001b[39m | \u001b[39m2.542    \u001b[39m | \u001b[39m206.1    \u001b[39m | \u001b[39m0.7728   \u001b[39m |\n",
      "| \u001b[39m106      \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.9721   \u001b[39m | \u001b[39m0.4049   \u001b[39m | \u001b[39m0.1564   \u001b[39m | \u001b[39m3.98     \u001b[39m | \u001b[39m1.814    \u001b[39m | \u001b[39m206.1    \u001b[39m | \u001b[39m0.8581   \u001b[39m |\n",
      "| \u001b[39m107      \u001b[39m | \u001b[39m0.7341   \u001b[39m | \u001b[39m0.9912   \u001b[39m | \u001b[39m0.4185   \u001b[39m | \u001b[39m0.01648  \u001b[39m | \u001b[39m3.553    \u001b[39m | \u001b[39m5.381    \u001b[39m | \u001b[39m134.8    \u001b[39m | \u001b[39m0.966    \u001b[39m |\n",
      "| \u001b[39m108      \u001b[39m | \u001b[39m0.7365   \u001b[39m | \u001b[39m0.7001   \u001b[39m | \u001b[39m0.3379   \u001b[39m | \u001b[39m0.2423   \u001b[39m | \u001b[39m9.526    \u001b[39m | \u001b[39m4.774    \u001b[39m | \u001b[39m195.7    \u001b[39m | \u001b[39m0.9347   \u001b[39m |\n",
      "| \u001b[39m109      \u001b[39m | \u001b[39m0.7371   \u001b[39m | \u001b[39m0.8384   \u001b[39m | \u001b[39m0.07196  \u001b[39m | \u001b[39m0.2981   \u001b[39m | \u001b[39m3.275    \u001b[39m | \u001b[39m8.057    \u001b[39m | \u001b[39m407.2    \u001b[39m | \u001b[39m0.9058   \u001b[39m |\n",
      "| \u001b[39m110      \u001b[39m | \u001b[39m0.7274   \u001b[39m | \u001b[39m0.9107   \u001b[39m | \u001b[39m0.04306  \u001b[39m | \u001b[39m0.06209  \u001b[39m | \u001b[39m9.466    \u001b[39m | \u001b[39m3.816    \u001b[39m | \u001b[39m413.8    \u001b[39m | \u001b[39m0.6396   \u001b[39m |\n",
      "=============================================================================================================\n",
      "Best parameters found:  {'colsample_bytree': 0.9748335207862212, 'gamma': 0.05138389167686236, 'learning_rate': 0.04919664347054723, 'max_depth': 3, 'min_child_weight': 9, 'n_estimators': 213, 'subsample': 0.6054018751524756}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.67      0.72      7090\n",
      "         1.0       0.71      0.81      0.75      7049\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.74      0.74      0.74     14139\n",
      "weighted avg       0.74      0.74      0.74     14139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, recall_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the function to optimize\n",
    "def xgb_cv(n_estimators, learning_rate, max_depth, min_child_weight, gamma, subsample, colsample_bytree):\n",
    "    # Define the model with the current parameters\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=int(n_estimators),\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=int(max_depth),\n",
    "        min_child_weight=int(min_child_weight),\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Perform cross-validation and calculate recall (macro average) as the score\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=make_scorer(recall_score, average='macro'))\n",
    "    return cv_scores.mean()\n",
    "\n",
    "# Define the parameter space for Bayesian Optimization\n",
    "param_bounds = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'max_depth': (3, 10),\n",
    "    'min_child_weight': (1, 10),\n",
    "    'gamma': (0, 0.5),\n",
    "    'subsample': (0.6, 1.0),\n",
    "    'colsample_bytree': (0.6, 1.0)\n",
    "}\n",
    "\n",
    "# Initialize the Bayesian Optimizer\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgb_cv,         # Function to optimize\n",
    "    pbounds=param_bounds,  # Parameter bounds\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Run the optimization\n",
    "optimizer.maximize(init_points=10, n_iter=100)\n",
    "\n",
    "# Extract the best parameters\n",
    "best_params = optimizer.max['params']\n",
    "best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "best_params['max_depth'] = int(best_params['max_depth'])\n",
    "best_params['min_child_weight'] = int(best_params['min_child_weight'])\n",
    "\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_xgb = XGBClassifier(**best_params, random_state=42)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "best_xgb_preds = best_xgb.predict(X_test)\n",
    "print(classification_report(y_test, best_xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   GenHlth               70692 non-null  category\n",
      " 1   HighBP                70692 non-null  category\n",
      " 2   BMI                   70692 non-null  float64 \n",
      " 3   HighChol              70692 non-null  category\n",
      " 4   Age                   70692 non-null  category\n",
      " 5   DiffWalk              70692 non-null  category\n",
      " 6   HeartDiseaseorAttack  70692 non-null  category\n",
      " 7   PhysHlth              70692 non-null  float64 \n",
      "dtypes: category(6), float64(2)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_infgain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Enhanced XGBoost with Additional Parameters\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "# 1. Enhanced XGBoost with better parameters\n",
    "def train_enhanced_xgboost(X_train, X_test, y_train, y_test):\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        min_child_weight=1,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=1,\n",
    "        tree_method='hist',  # Faster training\n",
    "        reg_alpha=0.1,       # L1 regularization\n",
    "        reg_lambda=1.0,      # L2 regularization\n",
    "        random_state=42\n",
    "    )\n",
    "    return evaluate_model(xgb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 2. LightGBM Implementation\n",
    "def train_lightgbm(X_train, X_test, y_train, y_test):\n",
    "    lgb_model = LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        feature_fraction=0.8,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    return evaluate_model(lgb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 3. Ensemble Method (Voting Classifier)\n",
    "def train_ensemble(X_train, X_test, y_train, y_test):\n",
    "    # Define base models\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    lgb = LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=7,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create voting classifier\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('xgb', xgb),\n",
    "            ('lgb', lgb),\n",
    "            ('rf', rf)\n",
    "        ],\n",
    "        voting='soft'\n",
    "    )\n",
    "    \n",
    "    return evaluate_model(ensemble, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 4. Feature Engineering and Preprocessing\n",
    "def preprocess_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Main execution\n",
    "def improve_model(X_train, X_test, y_train, y_test):\n",
    "    # 1. Preprocess the data\n",
    "    print(\"Preprocessing data...\")\n",
    "    X_train_scaled, X_test_scaled = preprocess_data(X_train, X_test)\n",
    "    \n",
    "    # 2. Try Enhanced XGBoost\n",
    "    print(\"\\nTraining Enhanced XGBoost...\")\n",
    "    xgb_model = train_enhanced_xgboost(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    # 3. Try LightGBM\n",
    "    print(\"\\nTraining LightGBM...\")\n",
    "    lgb_model = train_lightgbm(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    # 4. Try Ensemble\n",
    "    print(\"\\nTraining Ensemble Model...\")\n",
    "    ensemble_model = train_ensemble(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    return xgb_model, lgb_model, ensemble_model\n",
    "\n",
    "# Optional: Hyperparameter Tuning with RandomizedSearchCV\n",
    "def tune_xgboost(X_train, X_test, y_train, y_test):\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0, 0.1, 0.2]\n",
    "    }\n",
    "    \n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        xgb, param_distributions=param_dist,\n",
    "        n_iter=20, cv=5, scoring='accuracy',\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"Best parameters found:\", random_search.best_params_)\n",
    "    print(\"Best score:\", random_search.best_score_)\n",
    "    \n",
    "    return random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Training Enhanced XGBoost...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.68      0.72      7090\n",
      "         1.0       0.71      0.80      0.75      7049\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.74      0.74      0.74     14139\n",
      "weighted avg       0.74      0.74      0.74     14139\n",
      "\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 28297, number of negative: 28256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 50\n",
      "[LightGBM] [Info] Number of data points in the train set: 56553, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500362 -> initscore=0.001450\n",
      "[LightGBM] [Info] Start training from score 0.001450\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.67      0.72      7090\n",
      "         1.0       0.71      0.80      0.75      7049\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.74      0.74      0.74     14139\n",
      "weighted avg       0.74      0.74      0.74     14139\n",
      "\n",
      "\n",
      "Training Ensemble Model...\n",
      "[LightGBM] [Info] Number of positive: 28297, number of negative: 28256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 50\n",
      "[LightGBM] [Info] Number of data points in the train set: 56553, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500362 -> initscore=0.001450\n",
      "[LightGBM] [Info] Start training from score 0.001450\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.68      0.72      7090\n",
      "         1.0       0.71      0.80      0.75      7049\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.74      0.74      0.74     14139\n",
      "weighted avg       0.74      0.74      0.74     14139\n",
      "\n",
      "Best parameters found: {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Best score: 0.73948331323209\n"
     ]
    }
   ],
   "source": [
    "# Jalankan semua model\n",
    "xgb_model, lgb_model, ensemble_model = improve_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Atau tune XGBoost secara spesifik\n",
    "best_xgb = tune_xgboost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "# 1. Enhanced XGBoost with better parameters\n",
    "def train_enhanced_xgboost(X_train, X_test, y_train, y_test):\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        min_child_weight=1,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=1,\n",
    "        tree_method='hist',  # Faster training\n",
    "        reg_alpha=0.1,       # L1 regularization\n",
    "        reg_lambda=1.0,      # L2 regularization\n",
    "        random_state=42\n",
    "    )\n",
    "    return evaluate_model(xgb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 2. LightGBM Implementation\n",
    "def train_lightgbm(X_train, X_test, y_train, y_test):\n",
    "    lgb_model = LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        feature_fraction=0.8,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    return evaluate_model(lgb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 3. Ensemble Method (Voting Classifier)\n",
    "def train_ensemble(X_train, X_test, y_train, y_test):\n",
    "    # Define base models\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    lgb = LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=7,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create voting classifier\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[('xgb', xgb), ('lgb', lgb), ('rf', rf)],\n",
    "        voting='soft'\n",
    "    )\n",
    "    \n",
    "    return evaluate_model(ensemble, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 4. Feature Engineering and Preprocessing - Apply StandardScaler only to numeric columns\n",
    "def preprocess_data(X_train, X_test):\n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = X_train.select_dtypes(include=['category', 'object']).columns\n",
    "    \n",
    "    # Create transformers for both numeric and categorical columns\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values\n",
    "        ('scaler', StandardScaler())  # Standardize numeric columns\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding\n",
    "    ])\n",
    "    \n",
    "    # Combine both transformers into a single ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Apply transformations to both the train and test sets\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    return X_train_processed, X_test_processed\n",
    "\n",
    "# Main execution\n",
    "def improve_model(X_train, X_test, y_train, y_test):\n",
    "    # 1. Preprocess the data\n",
    "    print(\"Preprocessing data...\")\n",
    "    X_train_scaled, X_test_scaled = preprocess_data(X_train, X_test)\n",
    "    \n",
    "    # 2. Try Enhanced XGBoost\n",
    "    print(\"\\nTraining Enhanced XGBoost...\")\n",
    "    xgb_model = train_enhanced_xgboost(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    # 3. Try LightGBM\n",
    "    print(\"\\nTraining LightGBM...\")\n",
    "    lgb_model = train_lightgbm(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    # 4. Try Ensemble\n",
    "    print(\"\\nTraining Ensemble Model...\")\n",
    "    ensemble_model = train_ensemble(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "    return xgb_model, lgb_model, ensemble_model\n",
    "\n",
    "# Optional: Hyperparameter Tuning with RandomizedSearchCV\n",
    "def tune_xgboost(X_train, X_test, y_train, y_test):\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0, 0.1, 0.2]\n",
    "    }\n",
    "    \n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        xgb, param_distributions=param_dist,\n",
    "        n_iter=20, cv=5, scoring='accuracy',\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"Best parameters found:\", random_search.best_params_)\n",
    "    print(\"Best score:\", random_search.best_score_)\n",
    "    \n",
    "    return random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Training Enhanced XGBoost...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.71      0.74      7090\n",
      "         1.0       0.73      0.79      0.76      7049\n",
      "\n",
      "    accuracy                           0.75     14139\n",
      "   macro avg       0.75      0.75      0.75     14139\n",
      "weighted avg       0.75      0.75      0.75     14139\n",
      "\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 28297, number of negative: 28256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 157\n",
      "[LightGBM] [Info] Number of data points in the train set: 56553, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500362 -> initscore=0.001450\n",
      "[LightGBM] [Info] Start training from score 0.001450\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.71      0.74      7090\n",
      "         1.0       0.73      0.79      0.76      7049\n",
      "\n",
      "    accuracy                           0.75     14139\n",
      "   macro avg       0.75      0.75      0.75     14139\n",
      "weighted avg       0.75      0.75      0.75     14139\n",
      "\n",
      "\n",
      "Training Ensemble Model...\n",
      "[LightGBM] [Info] Number of positive: 28297, number of negative: 28256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 157\n",
      "[LightGBM] [Info] Number of data points in the train set: 56553, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500362 -> initscore=0.001450\n",
      "[LightGBM] [Info] Start training from score 0.001450\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.70      0.74      7090\n",
      "         1.0       0.73      0.79      0.76      7049\n",
      "\n",
      "    accuracy                           0.75     14139\n",
      "   macro avg       0.75      0.75      0.75     14139\n",
      "weighted avg       0.75      0.75      0.75     14139\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1500, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 521, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 958, in _create_dmatrix\n    return QuantileDMatrix(\n           ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 1529, in __init__\n    self._init(\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 1588, in _init\n    it.reraise()\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 576, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n    ^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 557, in _handle_exception\n    return fn()\n           ^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 641, in <lambda>\n    return self._handle_exception(lambda: self.next(input_data), 0)\n                                          ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 1280, in next\n    input_data(**self.kwargs)\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 624, in input_data\n    new, cat_codes, feature_names, feature_types = _proxy_transform(\n                                                   ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 1315, in _proxy_transform\n    arr, feature_names, feature_types = _transform_pandas_df(\n                                        ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 490, in _transform_pandas_df\n    _invalid_dataframe_dtype(data)\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 308, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:GenHlth: category, HighBP: category, HighChol: category, Age: category, DiffWalk: category, HeartDiseaseorAttack: category\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m xgb_model, lgb_model, ensemble_model \u001b[38;5;241m=\u001b[39m improve_model(X_train, X_test, y_train, y_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Atau tune XGBoost secara spesifik\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m best_xgb \u001b[38;5;241m=\u001b[39m \u001b[43mtune_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[63], line 156\u001b[0m, in \u001b[0;36mtune_xgboost\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m    149\u001b[0m xgb \u001b[38;5;241m=\u001b[39m XGBClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m    150\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m    151\u001b[0m     xgb, param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m    152\u001b[0m     n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    153\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    154\u001b[0m )\n\u001b[1;32m--> 156\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1500, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 521, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 958, in _create_dmatrix\n    return QuantileDMatrix(\n           ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 1529, in __init__\n    self._init(\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 1588, in _init\n    it.reraise()\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 576, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n    ^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 557, in _handle_exception\n    return fn()\n           ^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 641, in <lambda>\n    return self._handle_exception(lambda: self.next(input_data), 0)\n                                          ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 1280, in next\n    input_data(**self.kwargs)\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 624, in input_data\n    new, cat_codes, feature_names, feature_types = _proxy_transform(\n                                                   ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 1315, in _proxy_transform\n    arr, feature_names, feature_types = _transform_pandas_df(\n                                        ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 490, in _transform_pandas_df\n    _invalid_dataframe_dtype(data)\n  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 308, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:GenHlth: category, HighBP: category, HighChol: category, Age: category, DiffWalk: category, HeartDiseaseorAttack: category\n"
     ]
    }
   ],
   "source": [
    "# Jalankan semua model\n",
    "xgb_model, lgb_model, ensemble_model = improve_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Atau tune XGBoost secara spesifik\n",
    "best_xgb = tune_xgboost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Pandas DataFrame are not supported: apply X.values when calling fit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m clf\u001b[38;5;241m=\u001b[39m TabNetClassifier(optimizer_fn\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam,\n\u001b[0;32m      6\u001b[0m                        scheduler_params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m10\u001b[39m, \n\u001b[0;32m      7\u001b[0m                                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.9\u001b[39m},\n\u001b[0;32m      8\u001b[0m                        scheduler_fn\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR,\n\u001b[0;32m      9\u001b[0m                       )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# fit the model \u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbalanced_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m            \n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:217\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn \u001b[38;5;241m=\u001b[39m loss_fn\n\u001b[1;32m--> 217\u001b[0m \u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m check_warm_start(warm_start, from_unsupervised)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_fit_params(\n\u001b[0;32m    221\u001b[0m     X_train,\n\u001b[0;32m    222\u001b[0m     y_train,\n\u001b[0;32m    223\u001b[0m     eval_set,\n\u001b[0;32m    224\u001b[0m     weights,\n\u001b[0;32m    225\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\utils.py:506\u001b[0m, in \u001b[0;36mcheck_input\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mSeries)):\n\u001b[0;32m    505\u001b[0m     err_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas DataFrame are not supported: apply X.values when calling fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(err_message)\n\u001b[0;32m    507\u001b[0m check_array(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Pandas DataFrame are not supported: apply X.values when calling fit"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "\n",
    "# define the model\n",
    "clf= TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                       scheduler_params={\"step_size\":10, \n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                      )\n",
    "\n",
    "# fit the model \n",
    "clf.fit(\n",
    "    X_train,y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    eval_name=['train', 'test'],\n",
    "    eval_metric=['auc','balanced_accuracy'],\n",
    "    max_epochs=200, patience=60,\n",
    "    batch_size=512, virtual_batch_size=512,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
