{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all PDFs from the specified folder\n",
    "pdf_folder_path = \"../Data/\"\n",
    "all_pdf_paths = glob.glob(os.path.join(pdf_folder_path, \"*.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loaded document chunks: 1484\n"
     ]
    }
   ],
   "source": [
    "# Load each PDF document and split text\n",
    "documents = []\n",
    "for pdf_path in all_pdf_paths:\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pdf_docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    documents.extend(text_splitter.split_documents(pdf_docs))\n",
    "\n",
    "print(f\"Total loaded document chunks: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected document chunk:\n",
      "page_content='Penelitian pada pasien PPOK eksaserbasi rawat jalan \n",
      "menunjukkan hubungan antara purulensi sputum \n",
      "dengan terdapatnya bakteri. Penelitian PPOK eksaserbasi \n",
      "menggunakan ventilasi mekanis yang tidak diberikan \n",
      "antibiotik akan meningkatkan mortalitas dan \n",
      "meningkatnya angka kejadian pneumonia nosokomial. \n",
      "Antibiotik diberikan pada : \n",
      "a) Pasien PPOK eksaserbasi dengan semua gejala \n",
      "kardinal (sesak nafas yang bertambah,' metadata={'source': '../Data\\\\COPD-Kemenkes.pdf', 'page': 62}\n"
     ]
    }
   ],
   "source": [
    "# Display a random chunk for verification\n",
    "random_chunk = random.choice(documents)\n",
    "print(\"Randomly selected document chunk:\")\n",
    "print(random_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up embeddings and LLM with Google Gemini API\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GEMINI_API_KEY)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS vector database from documents\n",
    "vector_db = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with user and generate RAG answers\n",
    "def interact_with_user():\n",
    "    dataset = []  # List to store question and answer pairs for evaluation\n",
    "    \n",
    "    print(\"Hello! I'm here to answer your questions based on the documents.\")\n",
    "    while True:\n",
    "        # Ask the user for a question\n",
    "        question = input(\"Masukkan pertanyaan anda (or type 'exit' to quit): \")\n",
    "        \n",
    "        # Exit condition\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Retrieve relevant documents for the question\n",
    "        retrieved_docs = retriever.get_relevant_documents(question)\n",
    "        \n",
    "        # Prepare the prompt for Gemini LLM\n",
    "        prompt = f\"Berdasrkan informasi pada dokumen tentang penyakit PPOK, jawbalah pertanyaan berikut:\\n\\n\"\n",
    "        prompt += \"\\n\".join([doc.page_content for doc in retrieved_docs])  # Add content from retrieved docs\n",
    "        prompt += f\"\\n\\nQuestion: {question}\\nAnswer: \"\n",
    "        \n",
    "        # Generate answer from Gemini LLM\n",
    "        response = llm([HumanMessage(content=prompt)])\n",
    "        answer = response.content  # Extract the generated answer\n",
    "        \n",
    "        # Display the answer to the user\n",
    "        print(f\"Answer: {answer}\\n\")\n",
    "        \n",
    "        # Save the question and answer pair for future evaluation\n",
    "        dataset.append({\"question\": question, \"generated_answer\": answer})\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here to answer your questions based on the documents.\n",
      "Answer: PPOK adalah penyakit paru kronik yang ditandai oleh hambatan aliran udara di saluran nafas yang tidak sepenuhnya reversible. \n",
      "\n",
      "\n",
      "Answer: Berdasarkan informasi yang Anda berikan, berikut terminologi yang terkait dengan PPOK:\n",
      "\n",
      "**Gejala:**\n",
      "\n",
      "* **Sesak:** \n",
      "    * Progresif (sesak bertambah berat seiring berjalannya waktu)\n",
      "    * Bertambah berat dengan aktivitas\n",
      "    * Menetap sepanjang hari\n",
      "    * Dijelaskan oleh bahasa pasien sebagai \"Perlu usaha untuk bernafas,\"\n",
      "    * Berat, sukar bernafas, terengah-engah\n",
      "* **Batuk kronik:**\n",
      "    * Hilang timbul dan mungkin tidak berdahak\n",
      "    * Berdahak (Setiap batuk kronik berdahak dapat mengindikasikan PPOK)\n",
      "\n",
      "**Faktor Risiko:**\n",
      "\n",
      "* **Asap rokok**\n",
      "* **Polusi udara:** \n",
      "    * Dalam ruangan\n",
      "    * Luar ruangan\n",
      "* **Pajanan zat di tempat kerja**\n",
      "* **Genetik**\n",
      "* **Usia dan jenis kelamin**\n",
      "* **Tumbuh kembang paru**\n",
      "* **Sosial ekonomi**\n",
      "* **Infeksi paru berulang**\n",
      "* **Asma/hiperreaktivitas bronkus**\n",
      "* **Bronkitis kronik**\n",
      "\n",
      "**Lainnya:**\n",
      "\n",
      "* **Penyakit Paru Obstruktif Kronik (PPOK)**\n",
      "* **Bronkitis obstruktif**\n",
      "* **Emfisema**\n",
      "* **Asma**\n",
      "* **Resistensi**\n",
      "\n",
      "**Istilah lain yang mungkin terkait:**\n",
      "\n",
      "* **Pedoman Tata Laksana PPOK**\n",
      "* **Diagnosis dini**\n",
      "* **Tata laksana**\n",
      "* **Rehabilitasi**\n",
      "\n",
      "Semoga informasi ini membantu! \n",
      "\n",
      "\n",
      "Answer: Berdasarkan informasi yang diberikan, pada tahun 1990 PPOK menempati **urutan ke-6** sebagai penyebab utama kematian di dunia. \n",
      "\n",
      "\n",
      "Answer: Berdasarkan informasi pada dokumen, pada tahun 1990 PPOK menempati urutan **keenam** sebagai penyebab utama kematian di dunia. \n",
      "\n",
      "\n",
      "Answer: Biaya pengobatan PPOK di Amerika Serikat pada tahun 2010 sekitar **50 miliar Dollar AS**. \n",
      "\n",
      "\n",
      "Answer: Teks tersebut tidak menyebutkan jumlah kasus PPOK di Indonesia pada tahun 2006. Teks hanya menyebutkan prevalensi PPOK di Indonesia pada tahun 2012 sebesar 4,5%. \n",
      "\n",
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Start interaction with user\n",
    "generated_dataset = interact_with_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved for future evaluation.\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset (question, generated_answer) for future evaluation\n",
    "import json\n",
    "with open(\"./rag_evaluation_dataset.json\", \"w\") as f:\n",
    "    json.dump(generated_dataset, f, indent=4)\n",
    "\n",
    "print(\"Dataset saved for future evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Data yang ada\n",
    "rag_dataset = [\n",
    "    {\n",
    "        \"question\": \"apa itu PPOK\",\n",
    "        \"generated_answer\": \"PPOK adalah penyakit paru kronik yang ditandai oleh hambatan aliran udara di saluran nafas yang tidak sepenuhnya reversible. \\n\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Apa saja terminologi pada PPOK?\",\n",
    "        \"generated_answer\": \"Berdasarkan informasi yang Anda berikan, berikut terminologi yang terkait dengan PPOK:\\n\\n**Gejala:**\\n\\n* **Sesak:** \\n    * Progresif (sesak bertambah berat seiring berjalannya waktu)\\n    * Bertambah berat dengan aktivitas\\n    * Menetap sepanjang hari\\n    * Dijelaskan oleh bahasa pasien sebagai \\\"Perlu usaha untuk bernafas,\\\"\\n    * Berat, sukar bernafas, terengah-engah\\n* **Batuk kronik:**\\n    * Hilang timbul dan mungkin tidak berdahak\\n    * Berdahak (Setiap batuk kronik berdahak dapat mengindikasikan PPOK)\\n\\n**Faktor Risiko:**\\n\\n* **Asap rokok**\\n* **Polusi udara:** \\n    * Dalam ruangan\\n    * Luar ruangan\\n* **Pajanan zat di tempat kerja**\\n* **Genetik**\\n* **Usia dan jenis kelamin**\\n* **Tumbuh kembang paru**\\n* **Sosial ekonomi**\\n* **Infeksi paru berulang**\\n* **Asma/hiperreaktivitas bronkus**\\n* **Bronkitis kronik**\\n\\n**Lainnya:**\\n\\n* **Penyakit Paru Obstruktif Kronik (PPOK)**\\n* **Bronkitis obstruktif**\\n* **Emfisema**\\n* **Asma**\\n* **Resistensi**\\n\\n**Istilah lain yang mungkin terkait:**\\n\\n* **Pedoman Tata Laksana PPOK**\\n* **Diagnosis dini**\\n* **Tata laksana**\\n* **Rehabilitasi**\\n\\nSemoga informasi ini membantu! \\n\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"1990 PPOK  menempati urutan kematian keberapa dunia?\",\n",
    "        \"generated_answer\": \"Berdasarkan informasi yang diberikan, pada tahun 1990 PPOK menempati **urutan ke-6** sebagai penyebab utama kematian di dunia. \\n\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"pada tahun 1990 PPOK  menempati urutan kmetain keberapa di dunia\",\n",
    "        \"generated_answer\": \"Berdasarkan informasi pada dokumen, pada tahun 1990 PPOK menempati urutan **keenam** sebagai penyebab utama kematian di dunia. \\n\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \" Biaya pengobatan PPOK di Amerika Serikat pada tahun 2010 berapa?\",\n",
    "        \"generated_answer\": \"Biaya pengobatan PPOK di Amerika Serikat pada tahun 2010 sekitar **50 miliar Dollar AS**. \\n\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Tahun 2006 berapa kasus PPOK di Indoensia?\",\n",
    "        \"generated_answer\": \"Teks tersebut tidak menyebutkan jumlah kasus PPOK di Indonesia pada tahun 2006. Teks hanya menyebutkan prevalensi PPOK di Indonesia pada tahun 2012 sebesar 4,5%. \\n\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset gabungan telah disimpan sebagai rag_combined_evaluation_dataset.json.\n"
     ]
    }
   ],
   "source": [
    "# Jawaban yang diharapkan\n",
    "expected_answers = [\n",
    "    \"PPOK adalah penyakit paru kronik yang ditandai oleh hambatan aliran udara di saluran nafas yang tidak sepenuhnya reversible.\",\n",
    "    \"Terminologi pPOK meliputi PPOK dini, PPOK ringan, PPOK pada usia muda, Pra-PPOK, dan PRISm\",\n",
    "    \"Pada tahun 1990, PPOK menempati urutan ke-6 sebagai penyebab utama kematian di dunia.\",\n",
    "    \"Pada tahun 1990, PPOK menempati urutan keenam sebagai penyebab utama kematian di dunia.\",\n",
    "    \"Biaya pengobatan PPOK di Amerika Serikat pada tahun 2010 sekitar 50 miliar Dollar AS.\",\n",
    "    \"Teks tidak menyebutkan jumlah kasus PPOK di Indonesia pada tahun 2006, hanya menyebutkan prevalensi pada tahun 2012.\"\n",
    "]\n",
    "\n",
    "# Gabungkan data menjadi satu\n",
    "combined_data = []\n",
    "for idx, item in enumerate(rag_dataset):\n",
    "    combined_data.append({\n",
    "        \"question\": item[\"question\"],\n",
    "        \"generated_answer\": item[\"generated_answer\"],\n",
    "        \"expected_answer\": expected_answers[idx]\n",
    "    })\n",
    "\n",
    "# Simpan dataset gabungan dalam format JSON\n",
    "with open(\"./rag_combined_evaluation_dataset.json\", \"w\") as f:\n",
    "    json.dump(combined_data, f, indent=4)\n",
    "\n",
    "print(\"Dataset gabungan telah disimpan sebagai rag_combined_evaluation_dataset.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluasi RAG telah disimpan dalam rag_evaluation_results.json.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_answer_relevancy(generated_answer, expected_answer):\n",
    "    # Evaluasi relevansi: menggunakan persentase kecocokan kata-kata sebagai contoh sederhana\n",
    "    generated_set = set(generated_answer.lower().split())\n",
    "    expected_set = set(expected_answer.lower().split())\n",
    "    intersection = len(generated_set.intersection(expected_set))\n",
    "    total = len(expected_set)\n",
    "    return intersection / total if total > 0 else 0\n",
    "\n",
    "def evaluate_faithfulness(generated_answer, expected_answer):\n",
    "    # Evaluasi kesesuaian: menggunakan persentase kecocokan kalimat yang lebih ketat\n",
    "    return 1.0 if generated_answer.lower() == expected_answer.lower() else 0.0\n",
    "\n",
    "def evaluate_contextual_recall(generated_answer, expected_answer):\n",
    "    # Recall: Berapa banyak informasi yang relevan ditemukan dalam jawaban\n",
    "    return evaluate_answer_relevancy(generated_answer, expected_answer)\n",
    "\n",
    "def evaluate_contextual_precision(generated_answer, expected_answer):\n",
    "    # Precision: Seberapa banyak informasi yang dimasukkan dalam jawaban adalah relevan\n",
    "    return evaluate_answer_relevancy(generated_answer, expected_answer)\n",
    "\n",
    "def evaluate_contextual_relevancy(generated_answer, expected_answer):\n",
    "    # Kombinasi relevansi dan recall\n",
    "    return (evaluate_contextual_recall(generated_answer, expected_answer) + evaluate_contextual_precision(generated_answer, expected_answer)) / 2\n",
    "\n",
    "# Evaluasi dataset gabungan\n",
    "evaluations = []\n",
    "for data in combined_data:\n",
    "    generated_answer = data[\"generated_answer\"]\n",
    "    expected_answer = data[\"expected_answer\"]\n",
    "    \n",
    "    relevancy = evaluate_answer_relevancy(generated_answer, expected_answer)\n",
    "    faithfulness = evaluate_faithfulness(generated_answer, expected_answer)\n",
    "    recall = evaluate_contextual_recall(generated_answer, expected_answer)\n",
    "    precision = evaluate_contextual_precision(generated_answer, expected_answer)\n",
    "    relevancy_context = evaluate_contextual_relevancy(generated_answer, expected_answer)\n",
    "\n",
    "    evaluations.append({\n",
    "        \"question\": data[\"question\"],\n",
    "        \"relevancy\": relevancy,\n",
    "        \"faithfulness\": faithfulness,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"contextual_relevancy\": relevancy_context\n",
    "    })\n",
    "\n",
    "# Simpan hasil evaluasi\n",
    "with open(\"./rag_evaluation_results.json\", \"w\") as f:\n",
    "    json.dump(evaluations, f, indent=4)\n",
    "\n",
    "print(\"Evaluasi RAG telah disimpan dalam rag_evaluation_results.json.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsdn24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
